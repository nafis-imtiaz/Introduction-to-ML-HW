{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8461875-2962-449d-84dd-9c833df2f308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x204714f8510>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31f4f61-5264-413d-b063-8f71ac42d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4df08a4-d732-496e-a5ce-988da34bffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "data_path = 'E:/UNCC/UNCC ML/Project/data-unversioned/p1ch6/'\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "237fb3ee-493c-49a2-86d4-76321a23d8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29fdba3f-7fa6-431d-b819-05648500234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_map = {0: 0, 2: 1}\n",
    "label_map = {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9}\n",
    "#class_names = ['airplane', 'bird']\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10\n",
    "          if label in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5bebb0b-7d19-422b-b86b-d2245f43949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_chans):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,padding=1, bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight,nonlinearity='relu')\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "052301a1-9aa5-4c71-b828-944e0d5ac153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self, n_chans1=32, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.n_chans1 = n_chans1\n",
    "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
    "        self.resblocks = nn.Sequential(\n",
    "        *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
    "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
    "        self.fc2 = nn.Linear(32, 10)\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9860477-1053-48ad-a1bb-f38a2c4d1199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76074, [864, 32, 9216, 32, 32, 65536, 32, 320, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NetResDeep()\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "sum(numel_list), numel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e27b31b6-4a76-481e-8dd6-5e4e21f75a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5090, -0.6696, -1.6149,  0.1984, -1.4875,  0.4024,  0.4739, -0.8115,\n",
       "          2.0568, -1.1230]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, _ = cifar2[0]\n",
    "model = NetResDeep()\n",
    "model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "979d6fb2-71e1-4e3b-a8b7-7c27df0b8f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9297680c-0726-4767-a1e6-7265c3c2859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "        epoch_end_time = time.time()   \n",
    "        if epoch == 1 or epoch % 20 == 0:\n",
    "            print('{} Time Elapsed {}: Epoch {}, Training loss {}'.format(datetime.datetime.now(),(epoch_end_time - epoch_start_time), epoch, loss_train / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "437317a7-6289-4336-be6d-225deba290e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-09 22:44:59.747711 Time Elapsed 19.229727029800415: Epoch 1, Training loss 1.9328700008868256\n",
      "2024-12-09 22:50:45.994027 Time Elapsed 18.551975965499878: Epoch 20, Training loss 0.5881304409991299\n",
      "2024-12-09 22:56:48.965974 Time Elapsed 18.070319652557373: Epoch 40, Training loss 0.3869987768112126\n",
      "2024-12-09 23:02:50.083288 Time Elapsed 17.98607897758484: Epoch 60, Training loss 0.2767000024267118\n",
      "2024-12-09 23:08:51.923047 Time Elapsed 18.21383309364319: Epoch 80, Training loss 0.21373111720096202\n",
      "2024-12-09 23:14:57.089576 Time Elapsed 18.779070377349854: Epoch 100, Training loss 0.18429653117670342\n",
      "2024-12-09 23:21:07.128237 Time Elapsed 18.098594665527344: Epoch 120, Training loss 0.15046145342217707\n",
      "2024-12-09 23:27:11.876552 Time Elapsed 19.196884393692017: Epoch 140, Training loss 0.11413382206550696\n",
      "2024-12-09 23:33:12.737322 Time Elapsed 17.26853036880493: Epoch 160, Training loss 0.11061956615126375\n",
      "2024-12-09 23:39:14.329448 Time Elapsed 17.78671097755432: Epoch 180, Training loss 0.11374397821165354\n",
      "2024-12-09 23:45:28.196610 Time Elapsed 18.320668935775757: Epoch 200, Training loss 0.10334324539976161\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=32,shuffle=True)\n",
    "\n",
    "model = NetResDeep().to(device=device) #Instantiates our network with GPU \".to(device=device)\"\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2) #the stochastic gradient descent optimizer we have been working with\n",
    "loss_fn = nn.CrossEntropyLoss() #\n",
    "training_loop(\n",
    "    n_epochs = 200,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85469322-60ee-4e8a-a4e3-64b2b29d86a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.95\n",
      "Accuracy val: 0.67\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=32, shuffle=False)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=32,shuffle=False)\n",
    "\n",
    "def validate(model, train_loader, val_loader):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "validate(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e57ed1-6d29-4fa2-be43-5cfcbb6bec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
